%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                                                                                                             %
%                                                ▗▄▄▖▗▖ ▗▖ ▗▄▖ ▗▄▄▖▗▄▄▄▖▗▄▄▄▖▗▄▄▖     ▗▄▄▄▖▗▄▄▄▖▗▄▄▄▖                                                         %
%                                               ▐▌   ▐▌ ▐▌▐▌ ▐▌▐▌ ▐▌ █  ▐▌   ▐▌ ▐▌      █    █    █                                                           %
%                                               ▐▌   ▐▛▀▜▌▐▛▀▜▌▐▛▀▘  █  ▐▛▀▀▘▐▛▀▚▖      █    █    █                                                           %
%                                               ▝▚▄▄▖▐▌ ▐▌▐▌ ▐▌▐▌    █  ▐▙▄▄▖▐▌ ▐▌    ▗▄█▄▖▗▄█▄▖▗▄█▄▖                                                         %
%                                                                                                                                                             %
%         ▗▄▄▖  ▗▄▖ ▗▖ ▗▖  ▗▖▗▖  ▗▖ ▗▄▖ ▗▖  ▗▖▗▄▄▄▖ ▗▄▖ ▗▖       ▗▖    ▗▄▖▗▄▄▄▖▗▄▄▄▖▗▄▄▄▖ ▗▄▄▖▗▄▄▄▖    ▗▄▄▖ ▗▄▄▄▖▗▄▄▄ ▗▖ ▗▖ ▗▄▄▖▗▄▄▄▖▗▄▄▄▖ ▗▄▖ ▗▖  ▗▖         %
%         ▐▌ ▐▌▐▌ ▐▌▐▌  ▝▚▞▘ ▐▛▚▖▐▌▐▌ ▐▌▐▛▚▞▜▌  █  ▐▌ ▐▌▐▌       ▐▌   ▐▌ ▐▌ █    █    █  ▐▌   ▐▌       ▐▌ ▐▌▐▌   ▐▌  █▐▌ ▐▌▐▌     █    █  ▐▌ ▐▌▐▛▚▖▐▌         %
%         ▐▛▀▘ ▐▌ ▐▌▐▌   ▐▌  ▐▌ ▝▜▌▐▌ ▐▌▐▌  ▐▌  █  ▐▛▀▜▌▐▌       ▐▌   ▐▛▀▜▌ █    █    █  ▐▌   ▐▛▀▀▘    ▐▛▀▚▖▐▛▀▀▘▐▌  █▐▌ ▐▌▐▌     █    █  ▐▌ ▐▌▐▌ ▝▜▌         %
%         ▐▌   ▝▚▄▞▘▐▙▄▄▖▐▌  ▐▌  ▐▌▝▚▄▞▘▐▌  ▐▌▗▄█▄▖▐▌ ▐▌▐▙▄▄▖    ▐▙▄▄▖▐▌ ▐▌ █    █  ▗▄█▄▖▝▚▄▄▖▐▙▄▄▖    ▐▌ ▐▌▐▙▄▄▖▐▙▄▄▀▝▚▄▞▘▝▚▄▄▖  █  ▗▄█▄▖▝▚▄▞▘▐▌  ▐▌         %
%                                                                                                                                                             %
%                                            ▗▄▄▄▖▗▖  ▗▖▗▄▄▄▖▗▄▄▄▖ ▗▄▄▖▗▄▄▄▖▗▄▄▖      ▗▄▄▖ ▗▄▖  ▗▄▄▖▗▄▄▄▖                                                     %
%                                              █  ▐▛▚▖▐▌  █  ▐▌   ▐▌   ▐▌   ▐▌ ▐▌    ▐▌   ▐▌ ▐▌▐▌   ▐▌                                                        %
%                                              █  ▐▌ ▝▜▌  █  ▐▛▀▀▘▐▌▝▜▌▐▛▀▀▘▐▛▀▚▖    ▐▌   ▐▛▀▜▌ ▝▀▚▖▐▛▀▀▘                                                     %
%                                            ▗▄█▄▖▐▌  ▐▌  █  ▐▙▄▄▖▝▚▄▞▘▐▙▄▄▖▐▌ ▐▌    ▝▚▄▄▖▐▌ ▐▌▗▄▄▞▘▐▙▄▄▖                                                     %
%                                                                                                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                                                                                                             %
% Pas de sous-fichiers                                                                                                                                        %
%                                                                                                                                                             %
% Le fichier parent est : report.tex                                                                                                                          %
%                                                                                                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Adaptation de la réduction de réseaux polynomiaux au cas des réseaux euclidiens}

Ce chapitre constitue le cœur de mon stage. Il vise à explorer l’adaptation des techniques exactes de réduction de réseaux polynomiaux, au cadre des réseaux euclidiens. Il s'agit d’esquisser des pistes, de formuler des questions pertinentes et de suggérer des idées nouvelles. L’ensemble de ce travail a été réalisé en collaboration avec mon encadrant, Romain Lebreton.


\section{Fonction potentielle et bornes}

\subsection{Les cas polynomial}

Dans l’algorithme \hyperref[algo:WeakPopovForm]{\emph{\parencite{Mulders2003}}}, chaque opération entraîne soit une diminution du degré total par lignes, soit un déplacement du pivot d’une ligne vers la gauche.

\parencite{nielsen2013gmssr} définit une fonction de \emph{valeur} pour les vecteurs :
\[
\psi : 
\begin{array}{rcl}
    \mathbb{F}[x]^{\ell+1} & \longrightarrow & \mathbb{N}_0 \\
    \mathbf{v} & \longmapsto & (\ell + 1) \cdot \rdeg \mathbf{v} + \mathrm{LP}(\mathbf{v})
\end{array}
\]

où \( \mathrm{LP}(\mathbf{v} \) désigne l'indice du pivot de \( \mathbf{v} \).

\begin{lemma}
    Soit \( \mathbf{v}_j' \) le vecteur qui remplace \( \mathbf{v}_j \) lors d’une réduction de ligne dans \hyperref[algo:WeakPopovForm]{\emph{\parencite{Mulders2003}}}.
    Alors :
    \[
    \psi(\mathbf{v}_j') < \psi(\mathbf{v}_j).
    \]
\end{lemma}

Ainsi, l’algorithme \hyperref[algo:WeakPopovForm]{\emph{\parencite{Mulders2003}}} repose sur une fonction potentielle qui décroît strictement à chaque opération. Cette fonction atteint nécessairement une valeur minimale, correspondant à une situation où aucune opération supplémentaire n’est possible, c’est-à-dire lorsque la matrice est réduite en ligne. Cette même idée se traduit dans l'algorithme.

\subsection{Le cas entier}

Le lecteur pourra utilement se référer à la démonstration de la terminaison de l’algorithme \( \mathrm{LLL} \). Dans cette preuve, une quantité \( D \) a été introduite, qui décroît d’un facteur \( \frac{3}{4}\) à chaque échange de vecteurs. Cette décroissance strictement contrôlée constitue l’invariant principal garantissant la terminaison de l’algorithme.

\begin{definition}[Rappel]
    On définit \( \displaystyle D \coloneqq \prod_{1 \leq k < n} d_k = \prod_{1 \leq k < n} \| \bb_k^*\|^{2(n-k)}\)
\end{definition}

En pratique, la valeur de \( D \) peut devenir très grande, il est donc plus pertinent de regarder l’ordre de grandeur en considérant son logarithme \( \log(D) \), c’est-à-dire son nombre de bits, puisque c'est comme ça qu'il est considérer dans la démonstration.

\begin{proposition}
    \( \displaystyle \log(D) = \sum_{k=1}^{n-1} 2(n-k) \log (\| \bb_k^*\|)\)
\end{proposition}

On impose dans la preuve de terminaison que \( D \geq 1 \). Toutefois, \( D = 1 \) si et seulement si le réseau est isomorphe à \( \mathbb{Z}^n \). Un raisonnement similaire montre que très peu de réseaux satisfont \( D = 2 \). En pratique, la valeur de \( D \) reste largement supérieure à \( 1 \), et l’algorithme retourne une base \( \mathrm{LLL} \)-réduite avec \( D \gg 1 \). Ainsi, bien que le critère de terminaison repose sur une décroissance stricte de \( D \), cela ne reflète pas toujours le fait que l’algorithme a effectivement atteint un état suffisant de réduction.

On peut essayer d'améliorer la borne inférieure, on se place dans l'hypothèse que la base est \( \mathrm{LLL} \)-réduite et donc satisfait la condition de Lovàsz.

\[
\begin{aligned}
    D & = \prod_{1 \leq k < n} \| \bb_k^*\|^{2(n-k)} \\
      & = \|\bb_1^*\|^{2(n-1)} \x \|\bb_2^*\|^{2(n-2)} \x \cdots \x \|b_n^*\|^2 \\
      & \geq \|\bb_1^*\|^{2(n-1)} \x \left(\frac{\|\bb_1^*\|}{2}\right)^{2(n-2)} \x \cdots \x \left(\frac{\|\bb_1^*\|}{2^{n-2}}\right)^2 \\
      & \geq \left( \frac{\|b_1^*\|}{2^{\frac{4}{3} (n-2)}} \right)^{(n-1)n}
\end{aligned}
\]

Après la remise de ce rapport, mon travail consistera à explorer la portée pratique de cette borne. Contrairement au cas polynomial, le comportement de \( D \) dans le cas entier reste difficile à cerner, et l’on ne sait pas précisément jusqu’où cette quantité peut décroître.

De manière similaire au raisonnement précédent, une borne supérieure sur \( D \) est également disponible.  
Dans \parencite{MCA}, on trouve :
\[
D \leq \left( \max_{1 \leq i \leq n} \| \bg_i \| \right)^{n(n-1)}.
\]
Une question naturelle est alors de savoir si cette borne peut être améliorée. On peut voir que l'exposant \( n(n-1) \) peut devenir \( (n-1)n \). Plutôt que d'utiliser \( \max_{1 \leq i \leq n} \| \bg_i \| \), on pourrait utiliser un invariant lié au réseau comme \( |\LL| \). 

\section{Vers une réduction LLL adaptée aux réseaux d’approximation}


On va donner une définition équivalente du réseau d'approximation \( (F, \sigma) \) mais adaptée pour les réseaux euclidiens.

\begin{definition}
    Soit \( F \in M_n (\Z) \), un degré de précision \( \sigma \in \N\), et \(p \in \N\). On définit
    \[
    F_{p^\sigma} \coloneqq  \{ v \in \Z^n | vF = 0 \mod p^\sigma \}
    \]
\end{definition}

Contrairement au cas polynomial, la situation est ici fondamentalement différente. Nous verrons par la suite s’il est nécessaire d’imposer des restrictions sur \( p \) et \( \sigma \), et le cas échéant, lesquelles.

\begin{proposition}
    \( F_{p^\sigma} \) est un réseau euclidien de dimension \( n \).
\end{proposition}

\begin{remark}
    \( F_{p^\sigma} \) est un réseau \( p^\sigma\)-aire.
\end{remark}

Comment peut-on calculer une base de \( F_{p^\sigma} \)~? Est-il possible d’en extraire une base \( \mathrm{LLL} \)-réduite, et ce, de manière efficace~? Comme dans le cas polynomial traité pour le réseau \( (F, \sigma) \), il est d'abord nécessaire de calculer une décomposition \footnote{Il s’agit d’une généralisation de la décomposition \( P L F = U \), où \( U \) était une matrice triangulaire supérieure. Ici, on relâche cette contrainte en ne demandant que \( U \) soit échelonnée par lignes.} de la forme

\begin{equation}
\underbrace{
    \begin{bmatrix}
        e_{\tau(1)} \\
        \vdots \\
        e_{\tau(n)}
    \end{bmatrix}
}_{P}
\cdot
\underbrace{
    \begin{bmatrix}
        L_r & 0 \\
        G & I_{m-r}
    \end{bmatrix}
}_{L}
\cdot
F
=
\underbrace{
    \begin{bmatrix}
        E'\\
        0
    \end{bmatrix}
}_{E}
\end{equation}

où \(r \coloneqq \rang(F) \), \( P \) est une matrice de permutation, \( L \) est une matrice triangulaire inférieure et \( E \) est échelonnée en ligne.


\begin{smallalgo}{\textsc{PLE}$(A)$}{algo:ple}
    \KwIn{$A \in \mathbb{K}^{n \times m}$}
    \KwOut{Matrices \( P \), \( L \), \( E \) telles que \( 6.1 \) est satisfaite.}
    
    $n \gets \text{nrows}(A)$,\quad $m \gets \text{ncols}(A)$\;
    $P \gets I_n$, \quad $L \gets I_n$, \quad $E \gets A$\;
    
    \Pour{$i \gets 0$ \KwTo $m{-}1$}{
        $(\text{pivot}, i_{\text{pivot}}) \gets \textsc{Pivot}(E_{*,i}, \{i, \dots, n{-}1\})$\;
        
        \Si{$\text{pivot} = \texttt{None}$}{
            \textbf{continuer}
        }
        
        \Si{$i_{\text{pivot}} \neq i$}{
            Échanger les lignes $i$ et $i_{\text{pivot}}$ dans $P$ et $E$\;
            
            \Pour{$k \gets 0$ \KwTo $i{-}1$}{
                Échanger $L[i,k]$ et $L[i_{\text{pivot}},k]$\;
            }
        }
        
        \Pour{$j \gets i{+}1$ \KwTo $n{-}1$}{
            $s \gets E[j,i] / \text{pivot}$\;
            \Si{$s \neq 0$}{
                $E \gets E$ avec ligne $j$ \textbf{moins} $s$ fois ligne $i$\;
                $L \gets L$ avec ligne $j$ \textbf{moins} $s$ fois ligne $i$\;
            }
        }
    }
    
    \KwRet{$(P, L, E)$}
\end{smallalgo}

\begin{remark}

Comme c'est vrai pour toute permutations, il serait intéressant de choisir certaines permutations particulières, notamment qui ordonne les vecteurs par norme croissante.

\end{remark}

\begin{remark}
    J'ai mis trop d'investissement dans cet algorithme, j'en ai fais plusieurs versions, allant d'une version naïve où je calculais tous les pivots pour ordonner les lignes de façon à avoir les mineurs principaux inversibles, à une stratégie plus subtile d'échange quand nécessaire, grâce aux conseils avisés de mon encadrant. Cet algorithme fonctionne sur \( \Z_p \) pour \( p \) premier, car les pivots sont inversibles, je réfléchissais à une stratégie pour rendre cet algorithme fonctionnel  sur \( \Z_n \).
\end{remark}

\begin{theoreme}
    L'algorithme \textsc{PLE} calcule correctement une décomposition qui satisfait 6.1.
\end{theoreme}

\begin{counterexample}[Limite de l’algorithme \textsc{PLE}]
    L’algorithme \textsc{PLE} ne s’applique pas dans tous les cas. 
    
    Soit
    \[
    A =
    \begin{bmatrix}
        3 & 4 \\
        4 & 3
    \end{bmatrix}
    \in M_2(\mathbb{Z}/12\mathbb{Z}).
    \]
    Dans cet anneau, les coefficients \( 3 \) et \( 4 \) ne sont pas inversibles, ce qui empêche de procéder aux opérations de pivot nécessaires.\\
    
    Ce contre-exemple montre que la validité de l’algorithme repose sur une hypothèse cruciale : \emph{les pivots doivent être inversibles}.
\end{counterexample}



\begin{example}
    \[ \displaystyle
    \underbrace{\begin{pmatrix}
            1 & 0 & 0 & 0 \\
            -\frac{3}{4} & 1 & 0 & 0 \\
            -\frac{1}{2} & 0 & 1 & 0 \\
            0 & -\frac{1}{3} & 0 & 1
    \end{pmatrix}}_{L}
    \x
    \underbrace{
        \begin{pmatrix}
            1 & 0 & 0 & 0 \\
            0 & 0 & 1 & 0 \\
            0 & 1 & 0 & 0 \\
            0 & 0 & 0 & 1
        \end{pmatrix}
    }_{P}
    \underbrace{\begin{pmatrix}
            4 & 2 & 4 & 2 \\
            2 & 1 & 2 & 1 \\
            3 & 3 & 3 & 3 \\
            1 & 1 & 1 & 1
    \end{pmatrix}}_{F}
    =
    \underbrace{\begin{pmatrix}
            4 & 2 & 4 & 2 \\
            0 & \frac{3}{2} & 0 & \frac{3}{2} \\
            0 & 0 & 0 & 0 \\
            0 & 0 & 0 & 0
    \end{pmatrix}}_{E}
    \]
\end{example}


On en déduit donc un algorithme pour calculer une base.


De 6.1 on déduit que 

\[
\begin{bmatrix}
    e_{\tau(1)} \\
    \vdots \\
    e_{\tau(n)}
\end{bmatrix}
\cdot
\begin{bmatrix}
    L_r \cdot p^\sigma & 0 \\
    G & I_{m-r}
\end{bmatrix}
\cdot
F
=
\begin{bmatrix}
    E' \cdot p^\sigma\\
    0
\end{bmatrix}
=
\begin{bmatrix}
    0\\
    0
\end{bmatrix}
\mod p^\sigma
\]

\begin{theoreme}
    Les matrices
    \[
    \begin{bmatrix}
        L_r \cdot p^\sigma & 0 \\
        G & I_{m-r}
    \end{bmatrix}
    \cdot
    \begin{bmatrix}
        e_{\tau(1)} \\
        \vdots \\
        e_{\tau(n)}
    \end{bmatrix}
    , \quad
    \begin{bmatrix}
        I_r \cdot p^\sigma & 0 \\
        G & I_{m-r}
    \end{bmatrix}
    \cdot
    \begin{bmatrix}
        e_{\tau(1)} \\
        \vdots \\
        e_{\tau(n)}
    \end{bmatrix}
    \]
    sont deux bases de \( F_{p^\sigma}\)
\end{theoreme}

\begin{remark}
    Il vaut mieux privilégier la seconde base car les \(r\) premières lignes sont orthonormées, ce qui nous permet de déduire intuitivement que la base sera de meilleure qualité.
\end{remark}
%CA MARCHE QUE QUAND SIGMA VAUT 1
\begin{smallalgo}{\textsc{Basis}$(F, p, \texttt{mode})$}{algo:basis_modes}
    \KwIn{Une matrice \( F \in \mathbb{K}[x]^{m \times n} \), un scalaire \( p \in \mathbb{K} \), et une chaîne \texttt{mode} égale à \texttt{v1} ou \texttt{v2}}
    \KwOut{Une base transformée selon le mode choisi}
    
    $G \gets \text{copie}(F)$\;
    $(P, L, E) \gets \textsc{PLE}(G)$\;
    $r \gets \text{rang}(F)$\;
    
    \Si{\texttt{mode} = \texttt{v1}}{
        \Pour{$i \gets 0$ \KwTo $r{-}1$}{
            Multiplier la ligne $i$ de $L$ par $p$\;
        }
    }
    
    \Si{\texttt{mode} = \texttt{v2}}{
        \Pour{$i \gets 0$ \KwTo $r{-}1$}{
            Remplacer la ligne $i$ de $L$ par $p \cdot e_i$\;
            \tcp*{$e_i$ : $i$-ème vecteur de la base canonique}
        }
    }
    
    \KwRet{$L \cdot P$}
\end{smallalgo}


\begin{example}
    
    En partant de la matrice 
    \(
    F = 
    \begin{pmatrix}
        4 & 2 & 4 & 2 \\
        2 & 1 & 2 & 1 \\
        3 & 3 & 3 & 3 \\
        1 & 1 & 1 & 1
    \end{pmatrix}
    \)
    
    On peut calculer une base de \( F_{5^4}\)
    
    \[
        \begin{pmatrix}
            625 & 0 & 0 & 0 \\
            -\frac{1}{2} & 1 & 0 & 0 \\
            0 & 0 & 625 & 0 \\
            0 & 0 & -\frac{1}{3} & 1
        \end{pmatrix}
    \]
\end{example}

On peut donc maintenant définir un algorithme sur un principe diviser pour régner.  
\begin{smallalgo}{\textsc{LLL-DAC-Padique}$(F, p, \sigma)$}{algo:lll_dac_padic}
    \KwIn{$F \in \mathbb{K}^{m \times n}$, un entier premier $p$, un entier $\sigma \geq 1$}
    \KwOut{Une base "LLL-réduite?" en précision $p^\sigma$}
    
    \Si{$\sigma = 1$}{
        \KwRet{$\textsc{LLL}(\textsc{ApproximantBasis}(F, p))$}
    }
    
    $\tau \gets \left\lfloor \dfrac{\sigma + 1}{2} \right\rfloor$\;
    
    $V_1 \gets \textsc{LLL-DAC-Padique}(F, p, \tau)$ \tcp*[r]{Appel récursif sur demi-précision}
    
    $F_{\text{low}} \gets \dfrac{V_1 \cdot F}{p^\tau}$ \tcp*[r]{Mise à jour du problème}
    
    $V_2 \gets \textsc{LLL-DAC-Padique}(F_{\text{low}}, p, \sigma - \tau)$ \tcp*[r]{Appel récursif décalé}
    
    \KwRet{$V_2 \cdot V_1$}
\end{smallalgo}

Similairement à la preuve du chapitre précédent, \(V_2 V_1\) est une base de \( F_{p^\sigma} \).

\begin{problem}[\textbf{Question}]
    Dans quelle mesure le produit de matrices LLL-réduites reste-t-il lui-même LLL-réduit ? Peut-on quantifier cette propriété ?
\end{problem}

Si \( V_1 \) est une matrice orthogonale, c'est-à-dire dont les lignes sont orthonormées, alors \( V_2 V_1\) est \( \mathrm{LLL}\)-réduite.

On rappelle que \( V_1 = U_1 V_1^* \) d'après le procédé de Gram-Schmidt. En écrivant \( V_1 V_2 = V_1 V_2^* ((V_2^*)^{-1} U_2 V_2^*) \), peut-être pourront nous mieux contrôler le résultat du produit.

\section{Comprendre le rôle du shift dans le cas euclidien}

On rappel que calculer le degré de ligne décalé d'une matrice revient à calculer le degré de ligne de cette matrice multipliée à gauche par une matrice diagonale.

On pourrait ici définir une notion de décalage avec une matrice ligne-orthogonale. Cela a donné lieu à l'algorithme suivant que j'ai écris et dont j'ai prouvé la correction par moi-même.

\begin{smallalgo}{\textsc{shiftLLL}}{algo:shiftLLL}
    \KwIn{Une base \( G \) de \( \LL \), \( S^* \) une matrice ligne-orthogonale}
    \KwOut{Une base \( B \) de \( \LL \) tel que \( BS^* \) soit \( \mathrm{LLL} \)-réduite}
    
    \KwRet{ \( \mathrm{LLL}(G S^*) \cdot (S^*)^{-1} \) }
\end{smallalgo}


\begin{theoreme}
    L'algorithme \hyperref[algo:shiftLLL]{\emph{shiftLLL}} calcule correctement une base \( B \) du réseau \( \LL \) telle que \( BS^* \) soit \( \mathrm{LLL} \)-réduite.
\end{theoreme}

\begin{proof}
    On a le diagramme commutatif suivant en voyant \( S^* \) comme la matrice de passage de la base canonique \( \mathcal{C} \) à la base \( \mathcal{C'} \coloneqq S^* \). L'écriture \( \LL_{\mathcal{C}} \) où \( \mathcal{C} \) est une base représente \( \LL \) exprimée dans la base \( \mathcal{C} \).
     
    \[\begin{tikzcd}
        {\LL_{\mathcal{C}}} && {\LL_{\mathcal{C}}} \\
        \\
        && {\LL_{\mathcal{C}'}} 
        \arrow["G", from=1-1, to=1-3]
        \arrow["{GS^*}"', from=1-1, to=3-3]
        \arrow["{S^*}", from=1-3, to=3-3]
    \end{tikzcd}\]

    Comme \( LLL(GS^*) \) est une base de \( \LL_{\mathcal{C}'}\), on en déduit le diagramme commutatif suivant et donc que \( LLL(GS^*) (S^*)^{-1} \) est une base de \( \LL_{\mathcal{C}} \).
     
    \[\begin{tikzcd}
        {\LL_{\mathcal{C}}} && {\LL_{\mathcal{C}}} \\
        \\
        && {\LL_{\mathcal{C}'}}
        \arrow["{\mathrm{LLL}(GS^*)(S^*)^{-1}}", from=1-1, to=1-3]
        \arrow["{\mathrm{LLL}(GS^*)}"', from=1-1, to=3-3]
        \arrow["{S^*}", from=1-3, to=3-3]
    \end{tikzcd}\]

    On a par construction de \( \mathrm{LLL} \) que \( LLL(GS^*) (S^*)^{-1} S^*\) est \( \mathrm{LLL}\)-réduite.
\end{proof}

L'algorithme termine car \( \mathrm{LLL}\) termine et sa complexité est de l'ordre de la complexité de \( \mathrm{LLL}\).

En revenant à la décomposition précédente, en calculant une base telle que \(V_1 V_2^*\) est \( \mathrm{LLL}\)-réduite, c'est-à-dire \(V_1 \) est \( \mathrm{LLL}\)-réduite pour le décalage \(V_2^*\). On peut se poser les questions suivantes qui sont des pistes à explorer :

Est-ce que \( (V_2^*)^{-1} U_2 V_2 \) est "quasi" \( \mathrm{LLL}\)-réduite ?

\begin{problem}[Hypothèse]
    \( (V_2^*)^{-1} U_2 V_2 \) est une base propre, c'est-à-dire qu'en écrivant sa décomposition de Gram-Schmidt, les coefficients correspondant ne sont pas trop grand.
\end{problem}

La condition de Lovász peut être interprétée comme une forme de \(2\)-quasi-croissance.  
Une question naturelle serait alors de se demander si, par analogie, le produit calculé par LLL pourrait satisfaire une propriété de \(4\)-quasi-croissance.