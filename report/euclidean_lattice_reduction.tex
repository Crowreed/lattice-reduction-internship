%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                                                                                                             %
%                                        ▗▄▄▖▗▄▄▄▖ ▗▄▄▖▗▄▄▄▖▗▄▄▄▖ ▗▄▖ ▗▖  ▗▖    ▗▄▄▄▖▗▄▄▄▖        ▗▄▄▄▖▗▄▄▄▖                                                  %
%                                       ▐▌   ▐▌   ▐▌     █    █  ▐▌ ▐▌▐▛▚▖▐▌      █    █            █    █                                                    %
%                                        ▝▀▚▖▐▛▀▀▘▐▌     █    █  ▐▌ ▐▌▐▌ ▝▜▌      █    █            █    █                                                    %
%                                       ▗▄▄▞▘▐▙▄▄▖▝▚▄▄▖  █  ▗▄█▄▖▝▚▄▞▘▐▌  ▐▌    ▗▄█▄▖▗▄█▄▖        ▗▄█▄▖▗▄█▄▖                                                  %
%                                                                                                                                                             %
%         ▗▄▄▄▖▗▖ ▗▖ ▗▄▄▖▗▖   ▗▄▄▄▖▗▄▄▄ ▗▄▄▄▖ ▗▄▖ ▗▖  ▗▖    ▗▖    ▗▄▖▗▄▄▄▖▗▄▄▄▖▗▄▄▄▖ ▗▄▄▖▗▄▄▄▖    ▗▄▄▖ ▗▄▄▄▖▗▄▄▄ ▗▖ ▗▖ ▗▄▄▖▗▄▄▄▖▗▄▄▄▖ ▗▄▖ ▗▖  ▗▖              %
%         ▐▌   ▐▌ ▐▌▐▌   ▐▌     █  ▐▌  █▐▌   ▐▌ ▐▌▐▛▚▖▐▌    ▐▌   ▐▌ ▐▌ █    █    █  ▐▌   ▐▌       ▐▌ ▐▌▐▌   ▐▌  █▐▌ ▐▌▐▌     █    █  ▐▌ ▐▌▐▛▚▖▐▌              %
%         ▐▛▀▀▘▐▌ ▐▌▐▌   ▐▌     █  ▐▌  █▐▛▀▀▘▐▛▀▜▌▐▌ ▝▜▌    ▐▌   ▐▛▀▜▌ █    █    █  ▐▌   ▐▛▀▀▘    ▐▛▀▚▖▐▛▀▀▘▐▌  █▐▌ ▐▌▐▌     █    █  ▐▌ ▐▌▐▌ ▝▜▌              %
%         ▐▙▄▄▖▝▚▄▞▘▝▚▄▄▖▐▙▄▄▖▗▄█▄▖▐▙▄▄▀▐▙▄▄▖▐▌ ▐▌▐▌  ▐▌    ▐▙▄▄▖▐▌ ▐▌ █    █  ▗▄█▄▖▝▚▄▄▖▐▙▄▄▖    ▐▌ ▐▌▐▙▄▄▖▐▙▄▄▀▝▚▄▞▘▝▚▄▄▖  █  ▗▄█▄▖▝▚▄▞▘▐▌  ▐▌              %
%                                                                                                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                                                                                                             %
% Pas de sous-fichiers                                                                                                                                        %
%                                                                                                                                                             %
% Le fichier parent est : lattice_reduction.tex                                                                                                               %
%                                                                                                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\lettrine{D}{ans} ce chapitre, nous nous concentrerons sur un algorithme de réduction de réseaux euclidiens s’exécutant en temps polynomial : l’algorithme $\mathrm{LLL}$, du nom de ses auteurs A. Lenstra, H. Lenstra et L. Lovász. L'algorithme $\mathrm{LLL}$ possède de nombreuses applications, notamment en cryptanalyse de schémas basés sur le problème du sac à dos, en factorisation efficace de polynômes, ou encore dans le calcul rapide de décompositions en forme normale d'Hermite (HNF). Le lecteur pourra consulter \parencite{Havas1998} pour un aperçu plus complet de ses usages.  Nous ne traiterons pas d’autres algorithmes de réductions de réseaux euclidiens comme $\mathrm{BKZ}$, afin de rester dans un cadre plus élémentaire. L’algorithme $\mathrm{LLL}$ repose sur une idée simple mais puissante : il produit une approximation entière de la décomposition de Gram-Schmidt et réorganise les vecteurs de la base pour en améliorer la structure. Un rappel sur le procédé d’orthogonalisation de Gram-Schmidt est dans l’annexe dédiée. Celle-ci ne sera pas rappelée ici afin de préserver la concision du texte. Au cours de mon stage j'ai réalisé une présentation de l'algorithme LLL, ainsi qu'une idée rapide de sa preuve, que vous pourrez trouver ici.

\section{La base réduite}

Dans les problèmes liés aux réseaux euclidiens, une base orthogonale représenterait une base idéale.

\begin{problem}[\textbf{Problème}]
    La base \( B^* \) ( de $\R^n$ ) n'est généralement pas une base du réseau \( \LL(B) \).
\end{problem}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.23\textwidth]{images/lattice_0_9.png}
    \caption{ Base de Gram-Schmidt qui n'est pas une base de \( \LL \). }
    \label{fig:GS}
\end{figure}

Nous cherchons une base de \( \LL \) qui \emph{approxime} la base de Gram--Schmidt aussi fidèlement que possible.

\begin{notation}
    On définit l'entier le plus proche de $x \in \R$ par $\lceil x\rfloor  = \lfloor x+1/2 \rfloor$.
\end{notation}

\begin{proposition}
    On a $|x-\lceil x\rfloor| \leq \frac12$ pour tout $x \in \R$.
\end{proposition}

Dans la suite de cette explication, le lecteur est invité à porter une attention particulière aux * qui dénotent un vecteur de la base de Gram-Schmidt.
L'opération d'orthogonaliation de Gram-Schmidt nous donne :
\begin{equation}
    \mathbf{b}^*_2 \coloneqq \mathbf{b}_2 - \mu_{2,1} \mathbf{b}_1^* \notin \LL
\end{equation}

Mais \( \mathbf{b}_1^* = \mathbf{b}_1 \in \LL \), en prenant \( k \in \Z \), on a
\(
\mathbf{b}_2 - k \mathbf{b}_1 \in \LL
\), 
on pourrait donc réaliser l'opération
\[
\mathbf{b}_2 \coloneqq \mathbf{b}_2 - k \mathbf{b}_1 \in \LL
\]
On peut donc choisir \( k \in \Z \) qui minimise \( \left \langle \bb_2, \bb_1 \right \rangle \), ce qui est réalisé par \( k \coloneqq \nint{\mu_{i,j}}\). On en déduit donc l'opération 
\begin{equation}
    \mathbf{b}_2 \coloneqq  \mathbf{b}_2 - \nint{\mu_{2,1}} \mathbf{b}_1 \in \LL
\end{equation}

On peut donc étendre ce procédé par récurrence pour construire la nouvelle famille \( (\bb_i)_{1 \leq i \leq n} \).

En refaisant les calculs on peut montrer que la base de Gram-Schmidt associée est inchangée, mais que les nouveaux coefficients \( |\mu_{i,j}|<\frac12\) d'après la proposition 2.1.

\begin{figure}[H]
      \centering
      \includegraphics[width=0.23\textwidth]{images/lattice_1_9.png}
      \caption{ Base de \( \LL \) proche de la base Gram-Schmidt . }
      \label{fig:GS}
\end{figure}

\begin{definition}
	Soit \( (\bb_i)_{1 \leq i \leq n} \) une base d'un réseau et \( U \) la matrice triangulaire supérieure telle que \( B = UB^* \) .
    est dite \textbf{propre} \footnote{Une base propre est aussi connue sous le nom de base size-réduite dans la littérature.} si 
	
	\begin{equation}
		\displaystyle\max_{1 \leq i < j \leq n} |\mu_{i,j}| \leq \frac{1}{2}.
	\end{equation}
\end{definition}

\begin{counterexample}
    Bien que la proprification impose une certaine contrainte sur les coefficients de projection, elle ne garantit pas à elle seule que les vecteurs de la base soient presque orthogonaux.
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.23\textwidth]{images/lattice_0_10.png}
        \caption{ Base propre mais peu orthogonale }
        \label{fig:nosufficient}
    \end{figure}
\end{counterexample}

Idéalement, nous souhaiterions trouver une base \( (\bb_i)_{1 \leq i \leq n} \) du réseau \( \LL \) telle que :

\[
\| \bb_1 \| = \lambda_1(\LL), \quad
\| \bb_2 \| = \lambda_2(\LL), \quad \ldots, \quad
\| \bb_n \| = \lambda_n(\LL)
\]
Ceci implique \( \| \bb_1 \| \leq \cdots \leq \| \bb_n \|\), mais cela est trop difficile de trouver une telle base car cela reviendrait à résoudre SIVP.

\begin{definition}
    Une base \( (\bb_i)_{1 \leq i \leq m} \) satisfait la \textbf{condition de Lovász} \footnote{Une condition plus générale : \( ( \delta - \mu_{i+1,i}^2 ) \, \|\bb_i^*\|^2 \leq \|\bb_{i+1}^*\|^2 \text{ pour } 1 \leq i \leq n, \text{ où } \delta \in \left] \frac{1}{4}, 1 \right]  \) } si:
    \[
    \|\bb_i^*\|^2 \leq 2\|\bb_{i+1}^*\|^2 \quad \text{ pour tout } 1 \leq i < n
    \]
\end{definition}

\begin{remark}
    On peut interpréter cette condition comme une forme de quasi-croissance des normes \( \|\bb_i^*\| \) : elle n'exige pas que celles-ci soient strictement croissantes, mais impose que toute éventuelle décroissance soit contrôlée, autrement dit, qu'elles ne décroissent pas trop rapidement.
\end{remark}

Dès lors, il est naturel de se demander pourquoi ne pas échanger les vecteurs lorsque cette condition de Lovász n’est pas satisfaite.


\begin{example}
    Si l’on applique cette idée à l’exemple précédent, alors après permutation des vecteurs concernés et une nouvelle phase de réduction, on obtient à nouveau une base améliorée :
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.23\textwidth]{images/lattice_1_10.png}
        \caption{ Nouvelle base size-réduite}
        \label{fig:sufficient}
    \end{figure}
\end{example}


\begin{definition}
	Une base \( \mathcal{B} \) d'un réseau \( \LL (\mathcal{B}) \)  est dite \textbf{LLL-réduite} si
	\begin{itemize}
		\item[$\bullet$] $\mathcal{B}$ est propre.
		\item[$\bullet$] $\mathcal{B}$ satisfait la condition de Lovàsz.
	\end{itemize}
\end{definition}

\begin{remark}
	Chaque vecteur de la base réduite a une norme au moins égale à la moitié de celle du précédent, garantissant ainsi une décroissance modérée.
\end{remark}

\begin{theoreme}
	Soit \( \mathcal{B} \) une base réduite du réseau \( \LL \subseteq \R^n \) et soit \( v \in \LL \setminus \{0\} \). Alors
     \[ \|\bb_1\| \leq 2^{(n-1)/2} \cdot \|\bv\| \]
\end{theoreme}

En particulier, ce résultat s’applique à un vecteur \( \bv \in \LL \) de plus petite norme non nulle, c’est-à-dire un vecteur atteignant \( \lambda_1(\LL) \). On en déduit donc :
\[
\|\bb_1\| \leq 2^{(n-1)/2} \cdot \lambda_1(\LL),
\]
ce qui montre que \( \mathrm{LLL} \) fournit en temps polynomial un vecteur de norme à un facteur \( 2^{(n-1)/2} \) près du plus court vecteur du réseau.
Autrement dit, l’algorithme \( \mathrm{LLL} \) résout approximativement le problème du plus court vecteur (\( \mathrm{SVP} \)) avec un facteur d’approximation \( \gamma = 2^{(n-1)/2} \).
Par extension, en renvoyant les vecteurs de la base réduite, \( \mathrm{LLL} \) permet également de résoudre le problème \( \mathrm{SIVP} \) (\textit{Shortest Independent Vectors Problem}) avec le même facteur d’approximation.

\section{Fonctionnement et exemple}

Nous présentons à présent l’algorithme de Lenstra–Lenstra–Lovász (\( \mathrm{LLL} \)), dans sa forme classique. Originellement \( \mathrm{LLL} \) est apparu dans l'article de 1982 et servait à factoriser des polynômes à coefficients rationnels.

\begin{smallalgo}{LLL}{algo:LLL_MCA}
    \LinesNumbered 
    \DontPrintSemicolon
    \KwIn{Une base \( B = (\bb_1, \ldots, \bb_n) \)}
    \KwOut{Une base réduite \( G = (\bg_1, \ldots, \bg_n) \) de \( B \)}
    
    \For{\( i = 1 \) \KwTo \( n \)}{
        \( \bg_i \leftarrow \bb_i \)\;
    }
    
    \( (B^*, U) \leftarrow \) \textsc{Gram-Schmidt} \( (B) \)\;
    
    \While{\( i \leq n \)}
    {
        \For{\( j = i-1, i-2, \ldots, 1 \)}{
            \( \bg_i \leftarrow \bg_i - \nint{\mu_{i,j}} \, \bg_j \)\;
            Mettre à jour \( B^*, U  \)\;
        }
        
        \If{$i > 1$ \textbf{et} $\|\bg_{i-1}^*\|^2 > 2 \|\bg_{i}^*\|^2$}{
            Échanger \( \bg_{i-1} \) et \( \bg_i \)\;
            Mettre à jour \( B^*, U  \)\;
            \( i \leftarrow i - 1 \)\;
        }
        \Else{
            \( i \leftarrow i + 1 \)\;
        }
    }
    
    \KwRet{\( G = (\bg_1, \ldots, \bg_n) \)}
\end{smallalgo}

\vspace{1cm}
L’algorithme débute par le calcul de la base orthogonalisée de Gram–Schmidt (\textbf{ligne 3}), qui sert de support aux opérations de réduction.  
Le principe général repose sur l’application répétée de deux types d’étapes : des \emph{réductions de taille} (\textbf{lignes 5 à 7}) visant à raccourcir les vecteurs sans sortir du réseau, et des \emph{permutations} de vecteurs (\textbf{ligne 8}) effectuées lorsque la condition de Lovász, qui contrôle la décroissance des normes, n’est pas satisfaite.

L’ensemble de ces opérations est imbriqué dans une boucle \texttt{while} qui se répète tant qu’une condition de progression n’est pas remplie.  
Nous verrons que cette condition de Lovász garantit non seulement une amélioration à chaque étape, mais également la terminaison de l’algorithme en un nombre fini d’itérations.

\begin{example}
	Soit 
    \[
    B =
    \begin{pmatrix}
        1 & 1 & 1 \\
        -1 & 0 & 2 \\
        3 & 5 & 6
    \end{pmatrix}
    \in GL_3(\Z).
    \]
    On a $\displaystyle |\LL (B)| = 9, \quad A = \max_{1 \leq i \leq 3} \| \bb_i \| = 70$
    
    On va essayer d'estimer un plus court vecteur
    L'algorithme \hyperref[algo:LLL_MCA]{\emph{LLL}} commence par calculer la décomposition de Gram-Schmidt de \( B \), pour plus de détails sur le calcul de cette décomposition, ce calcul est effectué dans l'annexe \hyperref[appendix:linear_algebra]{\emph{Rappels d'algèbres linéaire }}.
    
    On obtient la décomposition
    
    \[
    \begin{aligned}
        U &= 
        \begin{pmatrix}
            1 & 0 & 0 \\
            \frac{1}{3} & 1 & 0 \\
            \frac{14}{3} & \frac{13}{14} & 1
        \end{pmatrix}, \quad
        B^* =
        \begin{pmatrix}
            1 & 1 & 1 \\
            -\frac{4}{3} & - \frac{1}{3} & \frac{5}{3} \\
            -\frac{3}{7} & \frac{9}{14} & - \frac{3}{14}
        \end{pmatrix}.
    \end{aligned}
    \] 
    
    Voici un tableau récapitulant les principales étapes de l'algorithme. Le tableau est volontairement détaillé et fourni, le lecteur pourra revenir sur cet exemple pour comprendre ce que sont $d_1$, $d_2$, $D$ ou la signification de $\Gram(G)$.
    
    \setlength{\tabcolsep}{0pt}
    
    \begin{center}
        \begin{tabular}{|c|c|c|c|c|c|} \hline % Premiere ligne
            \( G \)
            &
            \( U \)
            &
            \( G^* \)
            &
            \parbox[c][1cm][c]{1cm}
            {
                \centering
                \shortstack{\( d_1, d_2 \) \\ \( D \)}
            }
            & 
            \(
            \begin{pmatrix}
                \|\bg_1^*\|^2 \\
                \|\bg_2^*\|^2 \\
                \|\bg_3^*\|^2
            \end{pmatrix}
            \)
            &
            \( \Gram(G) \)
            \\
            \hline \tikzmark{l1} % Deuxieme ligne
            \parbox[c][2.2cm][c]{3cm}
            {%
                \[
                \begin{pmatrix}
                    1\quad 1\quad 1 \\
                    -1\quad 0\quad 2\\
                    3\quad 5\quad 6
                \end{pmatrix}
                \] 
            }
            & 
            \(
            \begin{pmatrix}
                1            & 0             & 0 \\
                \frac{1}{3}  & 1             & 0 \\
                \frac{14}{3} & \frac{13}{14} & 1
            \end{pmatrix}
            \) 
            & 
            \( 
            \begin{pmatrix}
                1            & 1            & 1 \\
                -\frac{4}{3} & -\frac{1}{3} & \frac{5}{3} \\
                -\frac{3}{7} & \frac{9}{14} & - \frac{3}{14}
            \end{pmatrix}
            \) 
            & 
            \parbox[c][0.9cm][c]{0.9cm}
            {
                \centering
                \shortstack{\( 3, 14 \) \\ \( 42 \)}
            }
            &
            \( 
            \begin{pmatrix}
                3 \\
                \frac{14}{3} \\
                \frac{9}{14}
            \end{pmatrix}
            \)
            &
            \(
            \begin{pmatrix}
                3 & 1 & 14 \\
                1 & 1 & 9 \\
                14 & 9 & 70
            \end{pmatrix}
            \)
            \\
            \hline \tikzmark{l2} % troisieme ligne
            \parbox[c][2.2cm][c]{3cm}
            {%
            \[
            \begin{pmatrix}
                1\quad 1\quad 1 \\
                -1\quad 0\quad 2\\
                0\quad 1\quad 0
            \end{pmatrix}
            \]
            }
            & 
            \(
            \begin{pmatrix}
                1           & 0             & 0 \\
                \frac{1}{3} & 1             & 0 \\
                \frac{1}{3} & \frac{-1}{14} & 1
            \end{pmatrix}
            \)
            & 
            \( 
            \begin{pmatrix}
                1 & 1 & 1 \\
                -\frac{4}{3} & -\frac{1}{3} & \frac{5}{3} \\
                -\frac{3}{7} & \frac{9}{14} & - \frac{3}{14}
            \end{pmatrix}
            \)
            &
            \parbox[c][0.9cm][c]{0.9cm}
            {
                \centering
                \shortstack{\( 3, 14 \) \\ \( 42 \)}
            }
            &
            \( 
            \begin{pmatrix}
                3 \\
                \frac{14}{3} \\
                \frac{9}{14}
            \end{pmatrix}
            \)
            &
              \(
            \begin{pmatrix}
                3 & 1 & 1 \\
                1 & 5 & 0 \\
                1 & 0 & 1
            \end{pmatrix}
            \)
            \\ \hline \tikzmark{l3}
            
            \parbox[c][1.6cm][c]{2.5cm}
            {%
                \centering
                \[
                \begin{pmatrix}
                    1& 1& 1 \\
                    0& 1& 0 \\
                    -1& 0& 2
                \end{pmatrix}
                \]
            }
            &
            \(
            \begin{pmatrix}
                1           & 0            & 0 \\
                \frac{1}{3} & 1            & 0 \\
                \frac{1}{3} & \frac{-1}{2} & 1
            \end{pmatrix}
            \) 
            & 
            \parbox[c][2.2cm][c]{3cm}
            {%
                
            \(
            \begin{pmatrix}
                1            & 1           & 1 \\
                -\frac{1}{3} & \frac{2}{3} & -\frac{1}{3} \\
                -\frac{3}{2} & 0           & \frac{3}{2}
            \end{pmatrix}
            \)
        }
            &
            \parbox[c][0.9cm][c]{0.9cm}
            {
                \centering
                \shortstack{\( 3, 2 \) \\ \( 6 \)}
            }
            &
            \( 
            \begin{pmatrix}
                3 \\
                \frac{2}{3} \\
                \frac{9}{2}
            \end{pmatrix}
            \)
            &
              \(
            \begin{pmatrix}
                1 & 0 & 0 \\
                0 & 1 & 0 \\
                \frac{1}{3} & \frac{-1}{2} & 1
            \end{pmatrix}
            \)
            \\
            \hline  \tikzmark{l4}
            \parbox[c][2.2cm][c]{3cm}
            {%
                \[
                \begin{pmatrix}
                    0& 1& 0 \\
                    1& 1& 1 \\
                    -1& 0& 2
                \end{pmatrix}
                \]
            }
            & 
            \( 
            \begin{pmatrix}
                1 & 0 & 0 \\
                1 & 1 & 0 \\
                \frac{1}{3} & \frac{-1}{2} & 1
            \end{pmatrix}
            \)
            & 
            \(
            \begin{pmatrix}
                0 & 1 & 0 \\
                1 & 0 & 1 \\
                -\frac{3}{2} & 0 & \frac{3}{2}
            \end{pmatrix}
            \)  
            &
            \parbox[c][0.9cm][c]{0.9cm}
            {
                \centering
                \shortstack{\( 1, 2 \) \\ \( 2 \)}
            }
            &
            \( 
            \begin{pmatrix}
                1 \\
                2 \\
                \frac{9}{2}
            \end{pmatrix}
            \)
            &
              \(
            \begin{pmatrix}
                1 & 0 & 0 \\
                0 & 1 & 0 \\
                \frac{1}{3} & \frac{-1}{2} & 1
            \end{pmatrix}
            \)
            \\
            \hline \tikzmark{l5}
            \parbox[c][2.2cm][c]{3cm}
            {%     
                \[
                \begin{pmatrix}
                    0 & 1 & 0 \\
                    1 & 0 & 1 \\
                    -1& 0 & 2
                \end{pmatrix}
                \]
            }
            & 
            \(
            \begin{pmatrix}
                1 & 0 & 0 \\
                0 & 1 & 0 \\
                \frac{1}{3} & \frac{-1}{2} & 1
            \end{pmatrix}
            \) 
            & 
            \(
            \begin{pmatrix}
                0 & 1 & 0 \\
                1 & 0 & 1 \\
                -\frac{3}{2} & 0 & \frac{3}{2}
            \end{pmatrix}
            \) 
            &
            \parbox[c][0.9cm][c]{0.9cm}
            {
                \centering
                \shortstack{\( 1, 2 \) \\ \( 2 \)}
            }
            &
            \( 
            \begin{pmatrix}
                1 \\
                2 \\
                \frac{9}{2}
            \end{pmatrix}
            \)
            &
            \(
            \begin{pmatrix}
                1 & 0 & 0 \\
                0 & 2 & 1 \\
                0 & 1 & 5
            \end{pmatrix}
            \)
            \\ \hline 
        \end{tabular}
    \end{center}

\vspace{1cm}

    On obtient la base  LLL réduite :

    \[
    \bg_{reduced}=
    \begin{pmatrix}
        0 & 1 & 0 \\
        1 & 0 & 1 \\
        -1 & 0 & 2
    \end{pmatrix}
    \in M_3(\Z) 
    \]



\end{example}


\begin{tikzpicture}[remember picture, overlay]
    \draw[->, thick, bend right=80]
    ([xshift=0em]pic cs:l1) to
    node[midway, left]{\small \shortstack{proprification\\ $\bg_3$}}
    ([xshift=0em, yshift=1em]pic cs:l2);
    
    \draw[->, thick, bend right=80]
    ([xshift=0em]pic cs:l2) to
    node[midway, left]{\small \shortstack{Lovasz\\ $\bg_2 \leftrightarrow \bg_3$}}
    ([xshift=0em, yshift=1em]pic cs:l3);
    
    \draw[->, thick, bend right=80]
    ([xshift=0em]pic cs:l3) to
    node[midway, left]{\small \shortstack{Lovasz\\ $\bg_1 \leftrightarrow \bg_2$}}
    ([xshift=0em, yshift=1em]pic cs:l4);
    
    \draw[->, thick, bend right=80]
    ([xshift=0em]pic cs:l4) to
    node[midway, left]{\small \shortstack{proprification\\ $\bg_2$}}
    ([xshift=0em, yshift=1em]pic cs:l5);
\end{tikzpicture}

\begin{remark}
    \leavevmode\vspace{0.5\baselineskip}
    \begin{itemize}
        \item[$\bullet$] La valeur $d_3$ ne nous intéresse pas car il s'agit d'un invariant, 
        \item[$\bullet$] \(Gram(G)\) se rapproche petit a petit d'une matrice diagonale.     
    \end{itemize}
\end{remark}

\chapter{Correction, terminaison et complexité de LLL}

Le lecteur pourra choisir de passer ce chapitre en première lecture. Les preuves et les résultats secondaires (lemmes et démonstrations annexes) sont regroupés en annexe afin d'alléger la lecture. Dans tous les cas, il suffira de garder à l'esprit que la terminaison de l'algorithme LLL repose sur la décroissance d'une quantité notée $D$, dont l'étude sera essentielle dans la suite. Le lecteur pourra également, s'il le souhaite, consulter directement les résultats relatifs à la complexité algorithmique de LLL.


\section{Correction}
\begin{theoreme}[Correction]
    L'algorithme \hyperref[algo:LLL_MCA]{\emph{LLL }} calcule une base réduite de \( \LL \).
\end{theoreme}

\vspace{0.2cm}
\begin{smallalgo}{Proprification de \( \bg_{i} \)}{step:P}
    \For{$j = i{-}1, i{-}2, \dots, 1$}{
        \hyperref[step:PP]{\emph{Proprification partielle de \( \bg_i \)}}\;
    }
\end{smallalgo}

\begin{lemma}
    \hyperref[step:P]{\emph{Proprification de $\bg_i$}} ne change pas $G^*$ et à la fin on a 
    \[
    |\mu_{i,l}| \leq \frac{1}{2} \text{ pour } 1 \leq l < i. 
    \]
\end{lemma}

On étudie maintenant l'étape de réduction, l'idée consiste à réorganiser les vecteurs afin de garantir une progression quantifiable, qui assurera la terminaison de LLL.

\vspace{0.2cm}
\begin{smallalgo}{Réduction de \( \bg_{i-1}, \bg_i \)}{step:R}
    \If{\( i > 1 \) \textbf{et} \( \norm{\bg_{i-1}^*}^2 > 2 \norm{\bg_{i}^*}^2 \)}
    {
        Échanger \( \bg_{i-1} \) et \( \bg_i \)\;
        
        Mettre à jour \( (B^*, U)  \)\;
        
        \( i \leftarrow i - 1 \)\;
    }
    \Else
    {
        \( i \leftarrow i + 1 \)\;
    }
\end{smallalgo}

\begin{lemma}
    Supposons que \( \bg_{i-1} \) et \( \bg_i \) sont échangés à l'étape \hyperref[step:R]{\emph{Réduction de $\bg_{i-1}, \bg_{i}$}}. 
    
    On note \( h_k \) les vecteurs après échange et \( h_k^* \) leur base orthogonale de Gram-Schmidt.
    
    Alors
    
    \begin{enumerate}
        \item \( \mathbf{h}_k^* = \bg_k^* \quad \text{pour tout } k \in \{1, \dots, n\} \setminus \{i-1, i\} \),
        \item \( \| \mathbf{h}_{i-1}^* \|^2 < \dfrac{3}{4} \| \bg_{i-1}^* \|^2 \),
        \item \( \| \mathbf{h}_i^* \| \leq \| \bg_{i-1}^* \| \).
    \end{enumerate}
\end{lemma}

\vspace{0.2cm}
\begin{smallalgo}{LLL}{step:LLL}
    \While{\( i \leq n \)}
    {
        \textit{Proprification de \( \bg_i \)}\;
        \textit{Réduction de \( \bg_{i-1}, \bg_i \)}\;
    }
\end{smallalgo}

\begin{lemma}
    Au début de chaque itération de la boucle à l'étape \hyperref[step:LLL]{\emph{LLL}}, les invariants suivants sont vérifiés :
    \[
    |\mu_{k,l}| \leq \frac{1}{2} \quad \text{pour } 1 \leq l < k < i, \qquad \|\bg_{k-1}^*\|^2 \leq 2 \|\bg_k^*\|^2 \quad \text{pour } 1 < k < i.
    \]
\end{lemma}

\section{Terminaison et complexité}
\begin{theoreme}[Terminaison et complexité]
    On pose \( \displaystyle A = \max_{1 \leq i \leq n} \| \bg_i \| \). L'algorithme \hyperref[algo:LLL_MCA]{\emph{LLL}} termine et utilise \( \OO(n^4 \log A) \) opérations arithmétiques sur des entiers.
\end{theoreme}

La difficulté est de montrer que la boucle Tant que ne va pas s'exécuter indéfiniment.

\begin{lemma}
    \leavevmode\vspace{0.3\baselineskip}
    \begin{enumerate}
        \item Orthogonalisation de Gram-Schmidt nécessite \( \OO(n^3) \) opérations dans \( \Z \).
        
        \item \hyperref[step:P]{\emph{Proprification de \( \bg_i \)}} nécessite \( \OO(n^2) \) opérations dans \( \Z \).
        
        \item \hyperref[step:R]{\emph{Réduction de \( \bg_{i-1}, \bg_{i} \)}} nécessite \( \OO(n) \) opérations dans \( \Z \).
    \end{enumerate}
\end{lemma}

Il reste à borner le nombre d'itérations de la boucle Tant que à l'étape \hyperref[step:LLL]{\emph{LLL}}. 

Pour tout \( 1 \leq k \leq n \), on pose
\[
\bg_k = 
\begin{pmatrix}
    \bg_1 \\
    \vdots \\
    \bg_k
\end{pmatrix}
\in \Z^{k \x n}
, \quad d_0=1, \quad d_k = \det(\bg_k \cdot \bg_k^T) \in \Z.
\]

\begin{lemma}
    Pour tout \( 1 \leq k \leq n \), on a :
    \[
    d_k = \prod_{1 \leq l \leq k} \| \bg_l^* \|^2 > 0.
    \]
\end{lemma}

\begin{lemma}
    \leavevmode\vspace{0.5\baselineskip}
    \begin{enumerate}
        \item \hyperref[step:P]{\emph{Proprification de \( \bg_i \)}} ne change pas \( d_k \)  pour tout \( 1 \leq k \leq n \).
        
        \item Si \( \bg_{i-1} \) et \( \bg_i \) sont échangés à l’étape \hyperref[step:P]{\emph{Réduction de \( \bg_{i-1}, \bg_{i} \)}}, et si \( d_k^* \) désigne la nouvelle valeur de \( d_k \), alors :
        \[
        d_k^* = d_k \quad \text{pour tout } k \neq i - 1, \quad \text{et} \quad d_{i-1}^* \leq \frac{3}{4} d_{i-1}.
        \]
    \end{enumerate}
\end{lemma}

\begin{proof}
    \begin{enumerate}
        \item D'après le lemme 2.2 \hyperref[step:P]{\emph{Proprification de \( \bg_i \)}} ne modifie pas \( \bg_k^* \) et donc ne modifie pas \( d_k \).
        
        \item Pour \( k \neq i-1\), une exécution de \hyperref[step:P]{\emph{Réduction de \( \bg_{i-1}, \bg_{i} \)}} multiplie \( \bg_k \) par une matrice de permutation, donc \( d_k^* = d_k \)
        
        De plus, on a
        \[
        d_{i-1} \eqjust{2.6} \prod_{1 \leq l \leq i-1} \| \bg_l^* \|^2 \leqjust{2.3} \frac{3}{4} \prod_{1 \leq l \leq i-1} \| \mathbf{h}_l^* \|^2 \eqjust{2.6} \frac{3}{4} d_{i-1}^* 
        \] 
    \end{enumerate}
\end{proof}
On pose
\[
D = \prod_{1 \leq k < n} d_k, \quad \displaystyle A = \max_{1 \leq i \leq n} \| \bg_i \|
\]

On désigne \( D_0 \) désigne la valeur de \( D \) au début de l'algorithme, on a \( 1 \leq D \in \Z \) et 

\[
\begin{aligned}
    D_0 &= \|\bg^*_1\|^{2(n-1)} \|\bg^*_2\|^{2(n-2)} \cdots \|\bg^*_{n-1}\|^2 \\
    &\leq \|\bg_1\|^{2(n-1)} \|\bg_2\|^{2(n-2)} \cdots \|\bg_{n-1}\|^2\\
    &\leq A^{n(n-1)}
\end{aligned} 
\] 


Puisque \( g^*_i \) est une projection de \( g_i \) pour tout \( i \). 

\begin{lemma}
    \leavevmode\vspace{0.5\baselineskip}
    \begin{enumerate}
        \item \hyperref[step:P]{\emph{Proprification de \( \bg_i \)}} ne modifie pas \( D \).
        \item \( D \) diminue d’au moins un facteur \( 3/4 \) si un échange a lieu dans \hyperref[step:R]{\emph{Réduction de \( \bg_{i-1}, \bg_{i} \)}}
    \end{enumerate}
\end{lemma}

\begin{proof}
    \begin{enumerate}
        \item D'après le lemme 2.7 \hyperref[step:P]{\emph{Proprification de \( \bg_i \)}} ne modifie pas \( d_k \) et donc ne modifie pas \( D \).
        
        \item Si \( \bg_{i-1} \) et \( \bg_i \) sont échangés lors de l'exécution de \hyperref[step:R]{\emph{Réduction de \( \bg_{i-1}, \bg_{i} \)}}, en notant \( D^* \) la nouvelle valeur de \( D \), alors d'après le lemme 2.7
        
        \[
        d_k^* = d_k, \quad d_{i-1}^* \leq \frac{3}{4} d_{i-1} \text{ donc } D^* \leq \frac{3}{4} D.
        \]
    \end{enumerate}
\end{proof}

À tout moment de l’algorithme, soit \( e \in \N \) le nombre d’échanges effectués jusqu’à présent, et \( e^* \) le nombre de fois où la branche alternative (le \textit{else}) dans \hyperref[step:R]{\emph{Réduction de \( \bg_{i-1}, \bg_{i} \)}} a été prise.

\begin{lemma}
    On a
    \[
    e \leq \log_{4/3} D_0 \in \OO(n^2 \log A)
    \]
\end{lemma}

\begin{proof}
    Soit \( D_e \) la valeur de \( D \) après \( e \) échanges.
    
    On doit avoir
    \[
    1 \;\le\; D_e \; \le\;\left(\frac34\right)^{e} D_0 \le\; \left(\frac34\right)^{e}A^{\,n(n-1)}.
    \]
    
    En appliquant \( lo\bg_{3/4} \), aux extrémités de l'inégalité.
    
    \[
    0=\log_{3/4}(1) \;\ge\; e + \log_{3/4}(A^{\,n(n-1)})=e + n(n-1)\frac{\log A}{\log(3/4)}.
    \]
    
    On en déduit que \( e \; \leq n(n-1)\frac{\log A}{-\log(3/4)}\) et donc \( e \in \OO(n^2 \log A)\)
    
\end{proof}

\begin{proof}[Preuve de la terminaison et la complexité]
    
    Comme \( i \) est décrémenté de \( 1 \) lors d’un échange et incrémenté de \( 1 \) sinon l'entier \( i + e - e^* \) est constant tout au long de \hyperref[step:LLL]{\emph{LLL}}.
    
    Initialement \( i + e - e^* = 2 \) et à la fin de \hyperref[step:LLL]{\emph{LLL}} on a \( n + 1 + e - e^* = 2 \).
    On en déduit donc que \( e + e^* = 2e + n - 1 \in \OO(n^2 \log A) \).
    et donc d'après le lemme 2.5 le coût total de \hyperref[step:LLL]{\emph{LLL}} est \( \OO(n^2 \x n^2 \log A) \) opérations dans \( \Z \). Ce qui acheve la preuve.
\end{proof}

\chapter*{État de l'art de la réduction de réseaux euclidiens}
\addcontentsline{toc}{chapter}{État de l'art de la réduction de réseaux euclidiens et l'objectif de mon stage}

Voici une rétrospective structurée des avancées majeures dans la réduction de réseaux euclidiens.

\begin{itemize}
    \item[\textbf{1982}] \textbf{LLL} (Lenstra, Lenstra, Lovász) \parencite{Lenstra1982} introduisent le premier algorithme de réduction polynomial, basé sur une combinaison de \emph{size reduction} et d'une condition de Lovász. Il garantit :
    \[
    \|\bb_1\| \leq (4/3)^{(n-1)/2} \cdot \lambda_1(\LL), \quad \text{avec complexité binaire } \mathcal{O}(n^5 \beta^2)
    \]
    
    \item[\textbf{1991}] \textbf{BKZ} \parencite{Schnorr1994} introduit une approche par blocs. L’algorithme applique un solveur SVP de petite dimension \(\beta\) à des sous-blocs de la base :
    \[
    \|\bb_1\| \leq \gamma_\beta^{(n-1)/(\beta - 1)} \cdot \lambda_1(\LL)
    \]
    Le coût est exponentiel en \(\beta\) mais reste efficace pour \(\beta \leq 40\) en pratique.
    
    \item[\textbf{2009}] \textbf{L2} \parencite{Nguyen2009} améliore LLL sur le plan de la stabilité numérique, sans gain théorique majeur sur la qualité de la base. Complexité similaire à LLL, mais plus efficace pour des entrées en flottants.
    
    \item[\textbf{2011}] \textbf{$\tilde{L}_1$} \parencite{Novocin2011} propose une version rapide de LLL inspirée du GCD rapide de Knuth–Schönhage. Il introduit une stratégie récursive appelée \emph{Lift-Reduction} et atteint une complexité quasi-linéaire :
    \[
    \mathcal{O}\left(d^{5+\varepsilon} \beta + d^{\omega+1+\varepsilon} \beta^{1+\varepsilon} \right)
    \]
    avec une qualité comparable à LLL : \( \|\bb_1\| \leq 2^{\alpha n} \cdot |\LL|^{1/n} \).
    
    \item[\textbf{2011}] \textbf{Terminating BKZ}  \parencite{cryptoeprint:2011/198} propose une modélisation dynamique affine de BKZ. Ils montrent que même interrompu prématurément, BKZ garantit :
    \[
    \|\bb_1\| \leq 2^{\frac{\gamma_\beta(n-1)}{2(\beta - 1)} + \frac{3}{2}} \cdot |\LL|^{1/n}
    \]
    après seulement \( \mathcal{O}(n^3/\beta^2 \cdot \log \|B\|) \) appels à un solveur SVP.
    
    \item[\textbf{2019}] \textbf{KEF} \parencite{Kirchner2021}propose un algorithme heuristique récursif exploitant la \emph{Geometric Series Assumption} (GSA) pour guider la réduction. Il utilise des techniques de FFT et obtient une complexité heuristique :
    \[
    \widetilde{\mathcal{O}}(n^\omega \cdot \log \kappa(B))
    \]
    avec une qualité empirique équivalente à BKZ en grande dimension (\( n > 2000 \)).
    
    \item[\textbf{2023}] \textbf{Iterated Compression} \parencite{Ryan2023} présente un algorithme récursif fondé sur des opérations de compression stables, une métrique de \emph{drop}, et des profils dynamiques :
    \[
    \|\bb_1\| \leq 2^{\alpha n} \cdot |\LL|^{1/n}, \quad \|\bb_n^*\| \geq 2^{-\alpha n} \cdot |\LL|^{1/n}
    \]
    avec complexité heuristique :
    \[
    \mathcal{O}(n^\omega(C + n)^{1+\varepsilon}), \quad C = \log(\|B\| \cdot \|B^{-1}\|)
    \]
    
\end{itemize}
\begin{comment}
    \subsection*{Mesures de qualité}
    La qualité d’une base \( B = (\bb_1, \dots, \bb_n) \) se mesure par :
    \begin{itemize}
        \item La norme \( \|\bb_1\| \), en comparaison avec \( \lambda_1(L) \),
        \item Le \emph{facteur d’Hermite} : \( \frac{\|\bb_1\|}{\det(L)^{1/n}} \),
        \item La décroissance des \( \|\bb_i^*\| \) (orthogonalité), souvent modélisée par la GSA : \( \|\bb_i^*\| \approx a \cdot r^i \).
    \end{itemize}
    
    \subsection*{Applications}
    La réduction de réseau est centrale en :
    \begin{itemize}
        \item \textbf{Cryptanalyse} de RSA (Coppersmith), NTRU, LWE, FHE,
        \item \textbf{Algèbre effective}, systèmes diophantiens,
        \item \textbf{Optimisation discrète}.
    \end{itemize}
    
    \subsection*{Conclusion}
    L'évolution de la réduction de réseaux est marquée par un passage progressif :
    \begin{itemize}
        \item de méthodes \textbf{théoriques lentes mais garanties} (HKZ, LLL),
        \item vers des approches \textbf{rapides, heuristiques et massivement parallélisables} (KEF, Iterated Compression),
    \end{itemize}
    en maintenant un objectif constant : approcher au mieux \( \lambda_1(L) \) avec un coût algorithmique acceptable, même en très grande dimension.
    
    
\end{comment}
